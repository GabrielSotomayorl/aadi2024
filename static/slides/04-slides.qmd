---
title: "Clase 4 <br> Regresi√≥n Lineal Simple II"
subtitle: "An√°lisis Avanzado de Datos"
author: "Gabriel Sotomayor"
format: 
  revealjs:
    theme: [dark, custom.scss]
    slide-number: true
    auto-fit: true
    logo: images/logo.png
editor: visual
---

# Recordatorio de la clase anterior

## Recta de Regresi√≥n M√≠nimo-Cuadr√°tica {.smaller background-color="white"}

La regresi√≥n lineal simple se utiliza para describir la relaci√≥n entre dos variables, una independiente (explicativa) y una dependiente (respuesta), mediante una recta de regresi√≥n. A diferencia de la correlaci√≥n si asume una direccionalidad.  

#### F√≥rmula General {background-color="white"}

La recta de regresi√≥n se expresa como: 
$$
\hat{y} = a + bx
$$

**Pendiente ùëè:** Indica el cambio promedio en la variable respuestaùë¶por cada unidad de cambio en la variable explicativa ùë•.\
**Ordenada en el origen ùëé:** Representa el valor predicho deùë¶cuando ùë•= 0. S√≥lo tiene significado estad√≠stico cuando x toma valores cercanos a 0.

## Caracter√≠sticas de la Regresi√≥n {.smaller background-color="white"}

-   **Distinci√≥n entre variable explicativa y variable respuesta**:
    -   La regresi√≥n m√≠nimo-cuadr√°tica considera s√≥lo las distancias verticales de los puntos a la recta.
    -   Cambiar los papeles de las dos variables resulta en una recta de regresi√≥n distinta.

**Conexi√≥n entre correlaci√≥n y regresi√≥n**: - La pendiente de la recta de regresi√≥n m√≠nimo-cuadr√°tica se calcula como:

$$
  b = r \frac{s_y}{s_x}
$$

-   A lo largo de la recta de regresi√≥n:
    -   Un cambio de una desviaci√≥n t√≠pica en x provoca un cambio de r desviaciones t√≠picas en y.
    -   Cuando r = 1 o r = ‚àí1, el cambio en y predicho es igual al cambio en x.
    -   Si ‚àí1 ‚â§ r ‚â§ 1, el cambio en y es menor que el cambio en x.
    -   A menor correlaci√≥n, menor es la predicci√≥n de y en respuesta a x.

## Caracter√≠sticas de la Regresi√≥n {.smaller background-color="white"}

-   **Punto de paso de la recta de regresi√≥n**:
    -   La recta de regresi√≥n m√≠nimo-cuadr√°tica siempre pasa por el punto $(\bar{x}, \bar{y})$.

    -   La recta de regresi√≥n se describe completamente con $\bar{x}$, $s_x$, $\bar{y}$, $s_y$ y $r$.

    -   **Correlaci√≥n r y la fuerza de la relaci√≥n lineal**:

    -   El cuadrado de la correlaci√≥n, $r^2$, indica la fracci√≥n de la variaci√≥n de $y$ explicada por la recta de regresi√≥n.

    -   $r^2$ se utiliza para medir la calidad de la predicci√≥n proporcionada por la regresi√≥n.
-   **Relaci√≥n entre r y** $r^2$:
    -   Una correlaci√≥n perfecta ($r = \pm1$) implica que $r^2 = 1$, lo que significa que toda la variaci√≥n de $y$ se explica por la relaci√≥n lineal con $x$.
    -   Si $r = \pm0.7$, entonces $r^2 = 0.49$, indicando que aproximadamente la mitad de la variaci√≥n se explica con la relaci√≥n lineal.


## Evaluaciones {.dark-background}

**Tarea 1: 2 de septiembre (la pauta se subir√° hoy)**\
- Gesti√≥n de datos\
- Estad√≠stica bivariada\
**Prueba 1: 9 de Septiembre**\
- Uso de modelos en ciencias sociales\
- Estad√≠stica bivariada\
- Regresi√≥n lineal simple

## Objetivo de la sesi√≥n {.center background-color="white"}

Profundizar en la interpretaci√≥n de la regresi√≥n lineal simple y el an√°lisis de los residuos.

